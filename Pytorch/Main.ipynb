{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:28.757146300Z",
     "start_time": "2024-04-08T20:16:28.745901100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Imports and GPU check\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dataset_size = 5000  # Reduced dataset size for quicker training\n",
    "\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "METADATA_FILE = 'Pytorch/Data/musicnet_metadata.csv'\n",
    "AUDIO_DIR = 'Pytorch/Data/musicnet/musicnet/train_data'\n",
    "ANNOTATIONS_FILE = 'Pytorch/Data/musicnet/musicnet/train_labels'\n",
    "sample_rate = 44100\n",
    "num_samples = 22050"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:28.988022Z",
     "start_time": "2024-04-08T20:16:28.970697600Z"
    }
   },
   "id": "85af2c87b90209ab"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:29.171144600Z",
     "start_time": "2024-04-08T20:16:29.156159300Z"
    }
   },
   "id": "9bf9dc571ba556e4"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def train_single_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    for input ,target in data_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        # loss\n",
    "        prediction = model(input)\n",
    "        loss = loss_fn(prediction, target)\n",
    "        # backpropogation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss: {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:29.368078900Z",
     "start_time": "2024-04-08T20:16:29.350755200Z"
    }
   },
   "id": "102aee100de104b3"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def train(model, data_loader, loss_fn, optimizer, epochs, device):\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\")\n",
    "        train_single_epoch(model, data_loader, loss_fn, optimizer, device)\n",
    "        print(\"-----------------------------------------------\")\n",
    "    print(\"Training completed!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:29.546281Z",
     "start_time": "2024-04-08T20:16:29.542689500Z"
    }
   },
   "id": "18da4c4fcecc1f53"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "labels_dir = os.path.join(project_dir, 'Data', 'musicnet', 'musicnet', 'train_labels')\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(labels_dir):\n",
    "    label_path = os.path.join(labels_dir, file)\n",
    "    df = pd.read_csv(label_path, index_col=None, header=0)\n",
    "    df['ID'] = int(file.split('.')[0])  # Extract ID from file name and add as a new column\n",
    "    dfs.append(df)\n",
    "\n",
    "train_dataframe = pd.concat(dfs, axis=0, ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:31.510265400Z",
     "start_time": "2024-04-08T20:16:29.776849400Z"
    }
   },
   "id": "2748cd1ac36c8d42"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   start_time  end_time  instrument  note  start_beat  end_beat  \\\n0        9182     90078          43    53         4.0       1.5   \n1        9182     33758          42    65         4.0       0.5   \n2        9182     62430           1    69         4.0       1.0   \n3        9182    202206          44    41         4.0       3.5   \n4        9182     62430           1    81         4.0       1.0   \n\n       note_value    ID  \n0  Dotted Quarter  1727  \n1          Eighth  1727  \n2         Quarter  1727  \n3           Whole  1727  \n4         Quarter  1727  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>instrument</th>\n      <th>note</th>\n      <th>start_beat</th>\n      <th>end_beat</th>\n      <th>note_value</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9182</td>\n      <td>90078</td>\n      <td>43</td>\n      <td>53</td>\n      <td>4.0</td>\n      <td>1.5</td>\n      <td>Dotted Quarter</td>\n      <td>1727</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9182</td>\n      <td>33758</td>\n      <td>42</td>\n      <td>65</td>\n      <td>4.0</td>\n      <td>0.5</td>\n      <td>Eighth</td>\n      <td>1727</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9182</td>\n      <td>62430</td>\n      <td>1</td>\n      <td>69</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>Quarter</td>\n      <td>1727</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9182</td>\n      <td>202206</td>\n      <td>44</td>\n      <td>41</td>\n      <td>4.0</td>\n      <td>3.5</td>\n      <td>Whole</td>\n      <td>1727</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9182</td>\n      <td>62430</td>\n      <td>1</td>\n      <td>81</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>Quarter</td>\n      <td>1727</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:31.529972400Z",
     "start_time": "2024-04-08T20:16:31.512789300Z"
    }
   },
   "id": "363d084f158f8430"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "   start_time  end_time  instrument  note  start_beat  end_beat  \\\n0       90078    124382           1    63         0.0     1.000   \n1       90078    124382           1    75         0.0     1.000   \n2       90078    110558           1    48         0.0     0.375   \n3      114654    122334           1    55         0.5     0.375   \n4      124382    139742           1    65         1.0     1.000   \n\n         note_value    ID  \n0           Quarter  1759  \n1           Quarter  1759  \n2  Dotted Sixteenth  1759  \n3  Dotted Sixteenth  1759  \n4           Quarter  1759  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>instrument</th>\n      <th>note</th>\n      <th>start_beat</th>\n      <th>end_beat</th>\n      <th>note_value</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90078</td>\n      <td>124382</td>\n      <td>1</td>\n      <td>63</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>Quarter</td>\n      <td>1759</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90078</td>\n      <td>124382</td>\n      <td>1</td>\n      <td>75</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>Quarter</td>\n      <td>1759</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>90078</td>\n      <td>110558</td>\n      <td>1</td>\n      <td>48</td>\n      <td>0.0</td>\n      <td>0.375</td>\n      <td>Dotted Sixteenth</td>\n      <td>1759</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>114654</td>\n      <td>122334</td>\n      <td>1</td>\n      <td>55</td>\n      <td>0.5</td>\n      <td>0.375</td>\n      <td>Dotted Sixteenth</td>\n      <td>1759</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>124382</td>\n      <td>139742</td>\n      <td>1</td>\n      <td>65</td>\n      <td>1.0</td>\n      <td>1.000</td>\n      <td>Quarter</td>\n      <td>1759</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = os.getcwd()\n",
    "labels_dir = os.path.join(project_dir, 'Data', 'musicnet', 'musicnet', 'test_labels')\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(labels_dir):\n",
    "    label_path = os.path.join(labels_dir, file)\n",
    "    df = pd.read_csv(label_path, index_col=None, header=0)\n",
    "    df['ID'] = int(file.split('.')[0])  # Extract ID from file name and add as a new column\n",
    "    dfs.append(df)\n",
    "\n",
    "test_dataframe = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "test_dataframe.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:16:31.677865200Z",
     "start_time": "2024-04-08T20:16:31.537498400Z"
    }
   },
   "id": "b4dd49dbc0823eef"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=2560, out_features=128, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch 1\n",
      "Loss: 4.85310697555542\n",
      "-----------------------------------------------\n",
      "Epoch 2\n",
      "Loss: 4.852045059204102\n",
      "-----------------------------------------------\n",
      "Epoch 3\n",
      "Loss: 4.849709510803223\n",
      "-----------------------------------------------\n",
      "Epoch 4\n",
      "Loss: 4.843362331390381\n",
      "-----------------------------------------------\n",
      "Epoch 5\n",
      "Loss: 4.822402477264404\n",
      "-----------------------------------------------\n",
      "Epoch 6\n",
      "Loss: 4.770640850067139\n",
      "-----------------------------------------------\n",
      "Epoch 7\n",
      "Loss: 4.709657192230225\n",
      "-----------------------------------------------\n",
      "Epoch 8\n",
      "Loss: 4.669087886810303\n",
      "-----------------------------------------------\n",
      "Epoch 9\n",
      "Loss: 4.637607574462891\n",
      "-----------------------------------------------\n",
      "Epoch 10\n",
      "Loss: 4.607917308807373\n",
      "-----------------------------------------------\n",
      "Epoch 11\n",
      "Loss: 4.559451580047607\n",
      "-----------------------------------------------\n",
      "Epoch 12\n",
      "Loss: 4.548522472381592\n",
      "-----------------------------------------------\n",
      "Epoch 13\n",
      "Loss: 4.507528305053711\n",
      "-----------------------------------------------\n",
      "Epoch 14\n",
      "Loss: 4.472650051116943\n",
      "-----------------------------------------------\n",
      "Epoch 15\n",
      "Loss: 4.438056945800781\n",
      "-----------------------------------------------\n",
      "Epoch 16\n",
      "Loss: 4.4465413093566895\n",
      "-----------------------------------------------\n",
      "Epoch 17\n",
      "Loss: 4.418134689331055\n",
      "-----------------------------------------------\n",
      "Epoch 18\n",
      "Loss: 4.412686824798584\n",
      "-----------------------------------------------\n",
      "Epoch 19\n",
      "Loss: 4.411190032958984\n",
      "-----------------------------------------------\n",
      "Epoch 20\n",
      "Loss: 4.41055965423584\n",
      "-----------------------------------------------\n",
      "Epoch 21\n",
      "Loss: 4.410200119018555\n",
      "-----------------------------------------------\n",
      "Epoch 22\n",
      "Loss: 4.409942150115967\n",
      "-----------------------------------------------\n",
      "Epoch 23\n",
      "Loss: 4.409714221954346\n",
      "-----------------------------------------------\n",
      "Epoch 24\n",
      "Loss: 4.409475326538086\n",
      "-----------------------------------------------\n",
      "Epoch 25\n",
      "Loss: 4.409215927124023\n",
      "-----------------------------------------------\n",
      "Epoch 26\n",
      "Loss: 4.408971309661865\n",
      "-----------------------------------------------\n",
      "Epoch 27\n",
      "Loss: 4.40880823135376\n",
      "-----------------------------------------------\n",
      "Epoch 28\n",
      "Loss: 4.408752918243408\n",
      "-----------------------------------------------\n",
      "Epoch 29\n",
      "Loss: 4.40872859954834\n",
      "-----------------------------------------------\n",
      "Epoch 30\n",
      "Loss: 4.408671855926514\n",
      "-----------------------------------------------\n",
      "Epoch 31\n",
      "Loss: 4.408615589141846\n",
      "-----------------------------------------------\n",
      "Epoch 32\n",
      "Loss: 4.408589839935303\n",
      "-----------------------------------------------\n",
      "Epoch 33\n",
      "Loss: 4.408581256866455\n",
      "-----------------------------------------------\n",
      "Epoch 34\n",
      "Loss: 4.408580303192139\n",
      "-----------------------------------------------\n",
      "Epoch 35\n",
      "Loss: 4.4085612297058105\n",
      "-----------------------------------------------\n",
      "Epoch 36\n",
      "Loss: 4.408504962921143\n",
      "-----------------------------------------------\n",
      "Epoch 37\n",
      "Loss: 4.408442974090576\n",
      "-----------------------------------------------\n",
      "Epoch 38\n",
      "Loss: 4.408412456512451\n",
      "-----------------------------------------------\n",
      "Epoch 39\n",
      "Loss: 4.408413887023926\n",
      "-----------------------------------------------\n",
      "Epoch 40\n",
      "Loss: 4.408420085906982\n",
      "-----------------------------------------------\n",
      "Epoch 41\n",
      "Loss: 4.40841007232666\n",
      "-----------------------------------------------\n",
      "Epoch 42\n",
      "Loss: 4.408393859863281\n",
      "-----------------------------------------------\n",
      "Epoch 43\n",
      "Loss: 4.408390522003174\n",
      "-----------------------------------------------\n",
      "Epoch 44\n",
      "Loss: 4.408397197723389\n",
      "-----------------------------------------------\n",
      "Epoch 45\n",
      "Loss: 4.408405303955078\n",
      "-----------------------------------------------\n",
      "Epoch 46\n",
      "Loss: 4.408407688140869\n",
      "-----------------------------------------------\n",
      "Epoch 47\n",
      "Loss: 4.408403396606445\n",
      "-----------------------------------------------\n",
      "Epoch 48\n",
      "Loss: 4.408393859863281\n",
      "-----------------------------------------------\n",
      "Epoch 49\n",
      "Loss: 4.40838098526001\n",
      "-----------------------------------------------\n",
      "Epoch 50\n",
      "Loss: 4.40836763381958\n",
      "-----------------------------------------------\n",
      "Training completed!!\n"
     ]
    }
   ],
   "source": [
    "from Pytorch.Dataset.MusicDataset import MusicDataset\n",
    "from Pytorch.Model.CNN import CNNNetwork\n",
    "# Example usage:\n",
    " # instantiate dataset\n",
    " \n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    " sample_rate=sample_rate,\n",
    "n_fft=1024,\n",
    "hop_length=512,\n",
    "n_mels=64\n",
    ")\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "train_data_dir = os.path.join(project_dir, 'Data', 'musicnet', 'musicnet', 'train_data')\n",
    "metadata_file = os.path.join(project_dir, 'Data', 'musicnet_metadata.csv')\n",
    "#labels_dir = os.path.join(project_dir, 'Data', 'musicnet', 'musicnet', 'train_labels')\n",
    "max_train_data_size = 1 * 1024 * 1024 * 1024  # 1GB in bytes\n",
    "\n",
    "train_dataset = MusicDataset(train_data_dir,train_dataframe,mel_spectrogram,\n",
    "                 sample_rate, num_samples, device, max_size_bytes=max_train_data_size)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_dataloader = create_data_loader(train_dataset, batch_size)\n",
    "\n",
    "cnn = CNNNetwork().to(device)\n",
    "print(cnn)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    " # train\n",
    "train(cnn, train_dataloader,loss_fn, optimizer, epochs,device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:21:38.734143Z",
     "start_time": "2024-04-08T20:21:03.570287Z"
    }
   },
   "id": "beb2c1bb1ff400da"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved at soundclassifier.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "torch.save(cnn.state_dict(), \"saved_model/soundclassifier.pth\")\n",
    "print(\"Trained model saved at soundclassifier.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.326998300Z",
     "start_time": "2024-04-08T20:17:00.319953900Z"
    }
   },
   "id": "22964c86b323fedd"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "instruments_map = {\n",
    "1: \"Acoustic Grand Piano\",\n",
    "2: \"Bright Acoustic Piano\",\n",
    "3: \"Electric Grand Piano\",\n",
    "4: \"Honky-tonk Piano\",\n",
    "5: \"Electric Piano 1\",\n",
    "6: \"Electric Piano 2\",\n",
    "7: \"Harpsichord\",\n",
    "8: \"Clavi\",\n",
    "9: \"Celesta\",\n",
    "10: \"Glockenspiel\",\n",
    "11: \"Music Box\",\n",
    "12: \"Vibraphone\",\n",
    "13: \"Marimba\",\n",
    "14: \"Xylophone\",\n",
    "15: \"Tubular Bells\",\n",
    "16: \"Dulcimer\",\n",
    "17: \"Drawbar Organ\",\n",
    "18: \"Percussive Organ\",\n",
    "19: \"Rock Organ\",\n",
    "20: \"Church Organ\",\n",
    "21: \"Reed Organ\",\n",
    "22: \"Accordion\",\n",
    "23: \"Harmonica\",\n",
    "24: \"Tango Accordion\",\n",
    "25: \"Acoustic Guitar (nylon)\",\n",
    "26: \"Acoustic Guitar (steel)\",\n",
    "27: \"Electric Guitar (jazz)\",\n",
    "28: \"Electric Guitar (clean)\",\n",
    "29: \"Electric Guitar (muted)\",\n",
    "30: \"Overdriven Guitar\",\n",
    "31: \"Distortion Guitar\",\n",
    "32: \"Guitar harmonics\",\n",
    "33: \"Acoustic Bass\",\n",
    "34: \"Electric Bass (finger)\",\n",
    "35: \"Electric Bass (pick)\",\n",
    "36: \"Fretless Bass\",\n",
    "37: \"Slap Bass 1\",\n",
    "38: \"Slap Bass 2\",\n",
    "39: \"Synth Bass 1\",\n",
    "40: \"Synth Bass 2\",\n",
    "41: \"Violin\",\n",
    "42: \"Viola\",\n",
    "43: \"Cello\",\n",
    "44: \"Contrabass\",\n",
    "45: \"Tremolo Strings\",\n",
    "46: \"Pizzicato Strings\",\n",
    "47: \"Orchestral Harp\",\n",
    "48: \"Timpani\",\n",
    "49: \"String Ensemble 1\",\n",
    "50: \"String Ensemble 2\",\n",
    "51: \"SynthStrings 1\",\n",
    "52: \"SynthStrings 2\",\n",
    "53: \"Choir Aahs\",\n",
    "54: \"Voice Oohs\",\n",
    "55: \"Synth Voice\",\n",
    "56: \"Orchestra Hit\",\n",
    "57: \"Trumpet\",\n",
    "58: \"Trombone\",\n",
    "59: \"Tuba\",\n",
    "60: \"Muted Trumpet\",\n",
    "61: \"French Horn\",\n",
    "62: \"Brass Section\",\n",
    "63: \"SynthBrass 1\",\n",
    "64: \"SynthBrass 2\",\n",
    "65: \"Soprano Sax\",\n",
    "66: \"Alto Sax\",\n",
    "67: \"Tenor Sax\",\n",
    "68: \"Baritone Sax\",\n",
    "69: \"Oboe\",\n",
    "70: \"English Horn\",\n",
    "71: \"Bassoon\",\n",
    "72: \"Clarinet\",\n",
    "73: \"Piccolo\",\n",
    "74: \"Flute\",\n",
    "75: \"Recorder\",\n",
    "76: \"Pan Flute\",\n",
    "77: \"Blown Bottle\",\n",
    "78: \"Shakuhachi\",\n",
    "79: \"Whistle\",\n",
    "80: \"Ocarina\",\n",
    "81: \"Lead 1 (square)\",\n",
    "82: \"Lead 2 (sawtooth)\",\n",
    "83: \"Lead 3 (calliope)\",\n",
    "84: \"Lead 4 (chiff)\",\n",
    "85: \"Lead 5 (charang)\",\n",
    "86: \"Lead 6 (voice)\",\n",
    "87: \"Lead 7 (fifths)\",\n",
    "88: \"Lead 8 (bass + lead)\",\n",
    "89: \"Pad 1 (new age)\",\n",
    "90: \"Pad 2 (warm)\",\n",
    "91: \"Pad 3 (polysynth)\",\n",
    "92: \"Pad 4 (choir)\",\n",
    "93: \"Pad 5 (bowed)\",\n",
    "94: \"Pad 6 (metallic)\",\n",
    "95: \"Pad 7 (halo)\",\n",
    "96: \"Pad 8 (sweep)\",\n",
    "97: \"FX 1 (rain)\",\n",
    "98: \"FX 2 (soundtrack)\",\n",
    "99: \"FX 3 (crystal)\",\n",
    "100: \"FX 4 (atmosphere)\",\n",
    "101: \"FX 5 (brightness)\",\n",
    "102: \"FX 6 (goblins)\",\n",
    "103: \"FX 7 (echoes)\",\n",
    "104: \"FX 8 (sci-fi)\",\n",
    "105: \"Sitar\",\n",
    "106: \"Banjo\",\n",
    "107: \"Shamisen\",\n",
    "108: \"Koto\",\n",
    "109: \"Kalimba\",\n",
    "110: \"Bag pipe\",\n",
    "111: \"Fiddle\",\n",
    "112: \"Shanai\",\n",
    "113: \"Tinkle Bell\",\n",
    "114: \"Agogo\",\n",
    "115: \"Steel Drums\",\n",
    "116: \"Woodblock\",\n",
    "117: \"Taiko Drum\",\n",
    "118: \"Melodic Tom\",\n",
    "119: \"Synth Drum\",\n",
    "120: \"Reverse Cymbal\",\n",
    "121: \"Guitar Fret Noise\",\n",
    "122: \"Breath Noise\",\n",
    "123: \"Seashore\",\n",
    "124: \"Bird Tweet\",\n",
    "125: \"Telephone Ring\",\n",
    "126: \"Helicopter\",\n",
    "127: \"Applause\",\n",
    "128: \"Gunshot\"\n",
    "}\n",
    "instruments_list = []\n",
    "for keys,values in instruments_map.items():\n",
    "    print(keys)\n",
    "    instruments_list.append(values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.356019700Z",
     "start_time": "2024-04-08T20:17:00.333092900Z"
    }
   },
   "id": "dc9aaf1ae9049480"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def predict(model, input, target, class_mapping):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input)\n",
    "        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n",
    "        predicted_index = predictions[0].argmax(0)\n",
    "        predicted = class_mapping[predicted_index]\n",
    "        expected = class_mapping[target]\n",
    "    return predicted, expected\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.356019700Z",
     "start_time": "2024-04-08T20:17:00.340691400Z"
    }
   },
   "id": "a8e9cab9294247f4"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 'Trombone', expected: 'Pan Flute'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_dict = torch.load(\"saved_model/soundclassifier.pth\")\n",
    "cnn.load_state_dict(state_dict)\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "test_data_dir = os.path.join(project_dir, 'Data', 'musicnet', 'musicnet', 'test_data')\n",
    "max_train_data_size = 1 * 1024 * 1024 * 1024  # 1GB in bytes\n",
    "\n",
    "test_dataset = NewDataset(test_data_dir,test_dataframe,mel_spectrogram,\n",
    "                 sample_rate, num_samples, device, max_size_bytes=max_train_data_size)\n",
    "\n",
    "# get a sample from the us dataset for inference\n",
    "input, target = test_dataset[1][0], test_dataset[1][1] # [num_cha, fr, t]\n",
    "input.unsqueeze_(0)\n",
    "# make an inference\n",
    "predicted, expected = predict(cnn, input, target,\n",
    "                              instruments_list)\n",
    "print(f\"Predicted: '{predicted}', expected: '{expected}'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.386256800Z",
     "start_time": "2024-04-08T20:17:00.348363200Z"
    }
   },
   "id": "199ef40f88530b4d"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.389990200Z",
     "start_time": "2024-04-08T20:17:00.387257700Z"
    }
   },
   "id": "d1e89c37570e044a"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.393994200Z",
     "start_time": "2024-04-08T20:17:00.390993300Z"
    }
   },
   "id": "f37c88d5d2cfe850"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.396848Z",
     "start_time": "2024-04-08T20:17:00.395328900Z"
    }
   },
   "id": "f61faf9e76b11272"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:17:00.401112300Z",
     "start_time": "2024-04-08T20:17:00.397902500Z"
    }
   },
   "id": "3eb817cad7227910"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f2953c6660142df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
